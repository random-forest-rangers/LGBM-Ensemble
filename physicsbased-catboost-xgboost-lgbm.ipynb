{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac49e963",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-07T21:09:29.814411Z",
     "iopub.status.busy": "2025-12-07T21:09:29.814110Z",
     "iopub.status.idle": "2025-12-07T21:09:42.911211Z",
     "shell.execute_reply": "2025-12-07T21:09:42.910061Z"
    },
    "papermill": {
     "duration": 13.103119,
     "end_time": "2025-12-07T21:09:42.913104",
     "exception": false,
     "start_time": "2025-12-07T21:09:29.809985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete. Ready to load data.\n"
     ]
    }
   ],
   "source": [
    "# 1. IMPORTS & SETUP\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Config\n",
    "DATA_DIR = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/\"\n",
    "TRAIN_PATH = DATA_DIR + 'train/'\n",
    "\n",
    "# We will load Weeks 1-9\n",
    "# but small enough to run quickly in the notebook.\n",
    "WEEKS = list(range(1, 10)) \n",
    "\n",
    "print(\"Setup Complete. Ready to load data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71d69ef5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T21:09:42.919366Z",
     "iopub.status.busy": "2025-12-07T21:09:42.918764Z",
     "iopub.status.idle": "2025-12-07T21:09:42.990309Z",
     "shell.execute_reply": "2025-12-07T21:09:42.989152Z"
    },
    "papermill": {
     "duration": 0.076571,
     "end_time": "2025-12-07T21:09:42.992024",
     "exception": false,
     "start_time": "2025-12-07T21:09:42.915453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Checking Week 1 ---\n",
      "\n",
      "INPUT Columns (Tracking Data):\n",
      "['game_id', 'play_id', 'player_to_predict', 'nfl_id', 'frame_id', 'play_direction', 'absolute_yardline_number', 'player_name', 'player_height', 'player_weight', 'player_birth_date', 'player_position', 'player_side', 'player_role', 'x', 'y', 's', 'a', 'dir', 'o', 'num_frames_output', 'ball_land_x', 'ball_land_y']\n",
      "\n",
      "OUTPUT Columns (Target Data):\n",
      "['game_id', 'play_id', 'nfl_id', 'frame_id', 'x', 'y']\n"
     ]
    }
   ],
   "source": [
    "#Check Column Names\n",
    "import pandas as pd\n",
    "\n",
    "# Load one week to peek at the structure\n",
    "w = 1\n",
    "path_in = f\"{TRAIN_PATH}input_2023_w{w:02d}.csv\"\n",
    "path_out = f\"{TRAIN_PATH}output_2023_w{w:02d}.csv\"\n",
    "\n",
    "try:\n",
    "    print(f\"--- Checking Week {w} ---\")\n",
    "    \n",
    "    # Read the first 5 rows\n",
    "    check_in = pd.read_csv(path_in, nrows=5)\n",
    "    check_out = pd.read_csv(path_out, nrows=5)\n",
    "    \n",
    "    print(\"\\nINPUT Columns (Tracking Data):\")\n",
    "    print(list(check_in.columns))\n",
    "    \n",
    "    print(\"\\nOUTPUT Columns (Target Data):\")\n",
    "    print(list(check_out.columns))\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Could not find files for Week {w}. Please check the path: {TRAIN_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88ef66fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T21:09:42.998695Z",
     "iopub.status.busy": "2025-12-07T21:09:42.998070Z",
     "iopub.status.idle": "2025-12-07T21:10:06.676088Z",
     "shell.execute_reply": "2025-12-07T21:10:06.674929Z"
    },
    "papermill": {
     "duration": 23.683327,
     "end_time": "2025-12-07T21:10:06.677886",
     "exception": false,
     "start_time": "2025-12-07T21:09:42.994559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Trajectory Data...\n",
      "Loaded Week 1\n",
      "Loaded Week 2\n",
      "Loaded Week 3\n",
      "Loaded Week 4\n",
      "Loaded Week 5\n",
      "Loaded Week 6\n",
      "Loaded Week 7\n",
      "Loaded Week 8\n",
      "Loaded Week 9\n",
      "Data Shape: (279727, 17)\n"
     ]
    }
   ],
   "source": [
    "# 2. DATA LOADING\n",
    "def load_data_trajectory(weeks):\n",
    "    df_list = []\n",
    "    for w in weeks:\n",
    "        try:\n",
    "            # Load Past (Input) and Future (Output)\n",
    "            df_in = pd.read_csv(f\"{TRAIN_PATH}input_2023_w{w:02d}.csv\")\n",
    "            df_out = pd.read_csv(f\"{TRAIN_PATH}output_2023_w{w:02d}.csv\")\n",
    "            \n",
    "            # 1. Create Physics Snapshot from Input\n",
    "            last_known = df_in.groupby(['game_id', 'play_id', 'nfl_id'], as_index=False).last()\n",
    "            \n",
    "            # Rename columns\n",
    "            last_known = last_known.rename(columns={\n",
    "                'x': 'start_x', 'y': 'start_y', 's': 'start_s', \n",
    "                'a': 'start_a', 'dir': 'start_dir', 'o': 'start_o'\n",
    "            })\n",
    "            \n",
    "            # 2. Merge Context onto the Future Frames\n",
    "            merged = df_out.merge(\n",
    "                last_known[[\n",
    "                    'game_id', 'play_id', 'nfl_id', \n",
    "                    'start_x', 'start_y', 'start_s', 'start_a', 'start_dir', 'start_o', \n",
    "                    'play_direction', \n",
    "                    'player_weight', 'player_height', \n",
    "                    'player_birth_date', 'player_role'\n",
    "                ]], \n",
    "                on=['game_id', 'play_id', 'nfl_id'], \n",
    "                how='left'\n",
    "            )\n",
    "            \n",
    "            df_list.append(merged)\n",
    "            print(f\"Loaded Week {w}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Week {w} not found.\")\n",
    "            \n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "print(\"Reloading Trajectory Data...\")\n",
    "train_df = load_data_trajectory(WEEKS)\n",
    "print(f\"Data Shape: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c67a851",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T21:10:06.685507Z",
     "iopub.status.busy": "2025-12-07T21:10:06.684803Z",
     "iopub.status.idle": "2025-12-07T21:10:07.416042Z",
     "shell.execute_reply": "2025-12-07T21:10:07.414531Z"
    },
    "papermill": {
     "duration": 0.737283,
     "end_time": "2025-12-07T21:10:07.417815",
     "exception": false,
     "start_time": "2025-12-07T21:10:06.680532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Features...\n",
      "Engineering Features...\n",
      "Generating One-Hot Encodings...\n",
      "Feature Engineering Complete.\n"
     ]
    }
   ],
   "source": [
    "# 3. FEATURE ENGINEERING\n",
    "def create_slide_features(df):\n",
    "    print(\"Engineering Features...\")\n",
    "    \n",
    "    # --- 0. PRE-PROCESSING ---\n",
    "    # Convert \"6-2\" to 74 inches\n",
    "    def parse_height(h):\n",
    "        try:\n",
    "            ft, inch = h.split('-')\n",
    "            return int(ft)*12 + int(inch)\n",
    "        except:\n",
    "            return 72 \n",
    "            \n",
    "    df['height_inches'] = df['player_height'].apply(parse_height)\n",
    "    \n",
    "    # --- 1. GEOMETRY ---\n",
    "    # Standardize to Left->Right\n",
    "    is_left = df['play_direction'] == 'left'\n",
    "    \n",
    "    df['std_x'] = np.where(is_left, 120 - df['x'], df['x'])\n",
    "    df['std_y'] = np.where(is_left, 53.3 - df['y'], df['y'])\n",
    "    df['std_start_x'] = np.where(is_left, 120 - df['start_x'], df['start_x'])\n",
    "    df['std_start_y'] = np.where(is_left, 53.3 - df['start_y'], df['start_y'])\n",
    "    df['std_dir'] = np.where(is_left, (df['start_dir'] + 180) % 360, df['start_dir'])\n",
    "    \n",
    "    # Normalize (0-1)\n",
    "    df['norm_start_x'] = df['std_start_x'] / 120.0\n",
    "    df['norm_start_y'] = df['std_start_y'] / 53.3\n",
    "    \n",
    "    # --- 2. PHYSICS ---\n",
    "    df['time_step'] = df['frame_id']\n",
    "    time_sec = df['time_step'] * 0.1\n",
    "    dir_rad = np.deg2rad(df['std_dir'])\n",
    "    \n",
    "    # Components\n",
    "    v_x = df['start_s'] * np.cos(dir_rad)\n",
    "    v_y = df['start_s'] * np.sin(dir_rad)\n",
    "    a_x = df['start_a'] * np.cos(dir_rad)\n",
    "    a_y = df['start_a'] * np.sin(dir_rad)\n",
    "    \n",
    "    # Kinematics (d = vt + 0.5at^2)\n",
    "    t_sq = time_sec ** 2\n",
    "    df['physics_dx'] = (v_x * time_sec) + (0.5 * a_x * t_sq)\n",
    "    df['physics_dy'] = (v_y * time_sec) + (0.5 * a_y * t_sq)\n",
    "    \n",
    "    # --- 3. BIOMECHANICS ---\n",
    "    df['momentum'] = df['player_weight'] * df['start_s']\n",
    "    df['kinetic_energy'] = 0.5 * df['player_weight'] * (df['start_s']**2)\n",
    "    \n",
    "    # BMI\n",
    "    df['bmi'] = 703 * df['player_weight'] / (df['height_inches']**2)\n",
    "    \n",
    "    # Age\n",
    "    game_year = df['game_id'].astype(str).str[:4].astype(int)\n",
    "    birth_year = pd.to_datetime(df['player_birth_date']).dt.year\n",
    "    df['age'] = game_year - birth_year\n",
    "    \n",
    "    # --- 4. TARGETS ---\n",
    "    df['target_dx'] = df['std_x'] - df['std_start_x']\n",
    "    df['target_dy'] = df['std_y'] - df['std_start_y']\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Processing Features...\")\n",
    "train_processed = create_slide_features(train_df)\n",
    "\n",
    "# One-Hot Encoding\n",
    "print(\"Generating One-Hot Encodings...\")\n",
    "train_processed = pd.get_dummies(train_processed, columns=['player_role'], prefix='role', dtype=int)\n",
    "role_features = [c for c in train_processed.columns if c.startswith('role_')]\n",
    "\n",
    "# Final Feature List\n",
    "FEATURES = [\n",
    "    'norm_start_x', 'norm_start_y', 'start_s', 'start_a', 'std_dir', \n",
    "    'time_step', 'player_weight', 'height_inches', 'age',\n",
    "    'physics_dx', 'physics_dy',       \n",
    "    'momentum', 'kinetic_energy', 'bmi' \n",
    "] + role_features\n",
    "\n",
    "TARGET_X = 'target_dx'\n",
    "TARGET_Y = 'target_dy'\n",
    "\n",
    "print(\"Feature Engineering Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46f0c7c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T21:10:07.425071Z",
     "iopub.status.busy": "2025-12-07T21:10:07.424593Z",
     "iopub.status.idle": "2025-12-07T21:21:09.768981Z",
     "shell.execute_reply": "2025-12-07T21:21:09.767963Z"
    },
    "papermill": {
     "duration": 662.353389,
     "end_time": "2025-12-07T21:21:09.774054",
     "exception": false,
     "start_time": "2025-12-07T21:10:07.420665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Standardized Ensemble Training...\n",
      "Fold 1 MSE: 2.2613\n",
      "Fold 2 MSE: 1.8526\n",
      "Fold 3 MSE: 1.8220\n",
      "Fold 4 MSE: 1.7767\n",
      "Fold 5 MSE: 1.9457\n",
      "\n",
      "========================================\n",
      "MODEL 2:  catboost+xgb+lgbm ensemble\n",
      "MSE:      1.9317\n",
      "RMSE: 1.3898\n",
      "MAE:     0.7116 yards\n",
      "R2:          0.9925\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# 4. ENSEMBLE TRAINING (PHYSICS + STANDARDIZED)\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "print(\"Starting Standardized Ensemble Training...\")\n",
    "\n",
    "# Hyperparameters (Low & Slow)\n",
    "xgb_params = {'objective': 'reg:squarederror', 'n_estimators': 1500, 'learning_rate': 0.02, 'max_depth': 7, 'tree_method': 'hist', 'n_jobs': -1, 'random_state': 42}\n",
    "lgb_params = {'objective': 'regression', 'n_estimators': 1500, 'learning_rate': 0.02, 'num_leaves': 40, 'n_jobs': -1, 'random_state': 42, 'verbose': -1}\n",
    "cat_params = {'iterations': 1500, 'learning_rate': 0.02, 'depth': 7, 'loss_function': 'RMSE', 'verbose': 0, 'allow_writing_files': False, 'random_seed': 42}\n",
    "\n",
    "groups = train_processed['game_id'].astype(str) + '_' + train_processed['play_id'].astype(str)\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "mse_scores = [] \n",
    "\n",
    "X = train_processed[FEATURES]\n",
    "y_x = train_processed[TARGET_X]\n",
    "y_y = train_processed[TARGET_Y]\n",
    "\n",
    "# We need the original 'play_direction' to un-flip the predictions for scoring\n",
    "play_directions = train_processed['play_direction']\n",
    "start_x_vals = train_processed['start_x'] # Original Start X\n",
    "start_y_vals = train_processed['start_y'] # Original Start Y\n",
    "true_x_vals = train_processed['x']        # Original True X\n",
    "true_y_vals = train_processed['y']        # Original True Y\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y_x, groups=groups), 1):\n",
    "    \n",
    "    # Slice Data\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    yx_train, yx_val = y_x.iloc[train_idx], y_x.iloc[val_idx]\n",
    "    yy_train, yy_val = y_y.iloc[train_idx], y_y.iloc[val_idx]\n",
    "    \n",
    "    # Train Models\n",
    "    lgb_x = lgb.LGBMRegressor(**lgb_params).fit(X_train, yx_train)\n",
    "    lgb_y = lgb.LGBMRegressor(**lgb_params).fit(X_train, yy_train)\n",
    "    xgb_x = xgb.XGBRegressor(**xgb_params).fit(X_train, yx_train)\n",
    "    xgb_y = xgb.XGBRegressor(**xgb_params).fit(X_train, yy_train)\n",
    "    cb_x = CatBoostRegressor(**cat_params).fit(X_train, yx_train)\n",
    "    cb_y = CatBoostRegressor(**cat_params).fit(X_train, yy_train)\n",
    "    \n",
    "    # Ensemble Prediction (Standardized Deltas)\n",
    "    pred_std_dx = (0.34 * lgb_x.predict(X_val)) + (0.33 * xgb_x.predict(X_val)) + (0.33 * cb_x.predict(X_val))\n",
    "    pred_std_dy = (0.34 * lgb_y.predict(X_val)) + (0.33 * xgb_y.predict(X_val)) + (0.33 * cb_y.predict(X_val))\n",
    "    \n",
    "    # --- RECONSTRUCTION ---\n",
    "    # Un-flip the delta to apply it to the REAL start position\n",
    "    val_dirs = play_directions.iloc[val_idx]\n",
    "    \n",
    "    real_dx = np.where(val_dirs == 'left', -pred_std_dx, pred_std_dx)\n",
    "    real_dy = np.where(val_dirs == 'left', -pred_std_dy, pred_std_dy)\n",
    "    \n",
    "    # Apply to Real Start Position\n",
    "    final_pred_x = start_x_vals.iloc[val_idx] + real_dx\n",
    "    final_pred_y = start_y_vals.iloc[val_idx] + real_dy\n",
    "    \n",
    "    # Score against Real Truth\n",
    "    mse_x = mean_squared_error(true_x_vals.iloc[val_idx], final_pred_x)\n",
    "    mse_y = mean_squared_error(true_y_vals.iloc[val_idx], final_pred_y)\n",
    "    total_mse = (mse_x + mse_y) / 2\n",
    "    \n",
    "    mse_scores.append(total_mse)\n",
    "    print(f\"Fold {fold} MSE: {total_mse:.4f}\")\n",
    "\n",
    "# --- METRIC CALCULATION ---\n",
    "\n",
    "# 1. MSE (Raw Error)\n",
    "mse_final = np.mean(mse_scores)\n",
    "\n",
    "# 2. RMSE (Standard Metric)\n",
    "rmse_final = np.sqrt(mse_final)\n",
    "\n",
    "# 3. MAE Using last fold data\n",
    "mae_x = mean_absolute_error(true_x_vals.iloc[val_idx], final_pred_x)\n",
    "mae_y = mean_absolute_error(true_y_vals.iloc[val_idx], final_pred_y)\n",
    "mae_final = (mae_x + mae_y) / 2\n",
    "\n",
    "# 4. R-Squared (Scientific Metric)\n",
    "r2_x = r2_score(true_x_vals.iloc[val_idx], final_pred_x)\n",
    "r2_y = r2_score(true_y_vals.iloc[val_idx], final_pred_y)\n",
    "r2_final = (r2_x + r2_y) / 2\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"MODEL 2:  catboost+xgb+lgbm ensemble\")\n",
    "print(f\"MSE:      {mse_final:.4f}\")\n",
    "print(f\"RMSE: {rmse_final:.4f}\")\n",
    "print(f\"MAE:     {mae_final:.4f} yards\")\n",
    "print(f\"R2:          {r2_final:.4f}\")\n",
    "print(\"=\"*40)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14210809,
     "sourceId": 114239,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 707.117033,
   "end_time": "2025-12-07T21:21:11.000278",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-07T21:09:23.883245",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
